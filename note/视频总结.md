### 计算机视觉引论
#### Linux入门简易教程
1. 看完之后我觉得大家都应该装 Linux的，至少装个虚拟机先吧，体验一下先
2. 如果对Linux不熟悉的学员还是有必要看看这个视频的
3. [视频下面的配套说明文档](https://dwsun.blog.csdn.net/article/details/90633971)里的terminator(终端会话管理软件)和shutter(截屏软件)可以装一下

#### 第一章~第二章 计算机视觉引论及数字成像系统
##### 第一章
![Selection_074](_v_images/20190730170212477_1559295311.png =506x)
1. 人的眼睛接收到外界信息，同时可以感受到不同物体之间的相对距离，也可以理解为深度信息，不是有个摄像头RGBD嘛，D就是Depth
2. 人、车、房子在什么位置涉及到目标检测，目标在做什么涉及到行为分析，目标之间的关系涉及到推理了吧，有个东西叫image caption

![人的视觉系统是分层处理的，对应于卷积神经网络的不同层](_v_images/20190730170742998_2104865931.png =508x)
1. 人的视觉系统是分层处理的，对应于卷积神经网络(用于图像分类和图像检测等)的不同层

![Selection_076](_v_images/20190730191440750_2052194942.png =506x)
上图为视觉系统构成要素
视觉系统中光照很重要，因为光照影响着图像信息的输入，所以有时候会用到补光灯(光补偿)

1. 改变图片大小
```
cv2.resize()
```

2. 图像平滑

![Selection_077](_v_images/20190730194740666_1078238160.png)
![Selection_078](_v_images/20190730194803070_1138395613.png)
![Selection_081](_v_images/20190730200706413_1715864653.png)
![Selection_079](_v_images/20190730194830710_1366430459.png)
![Selection_080](_v_images/20190730194850713_2013313934.png)
```
高斯平滑(滤波): 可以去除原始图片中的噪声，但是也会使图像变得模糊和透明，参考链接(https://en.wikipedia.org/wiki/Gaussian_blur)
cv2.GaussianBlur(img,(5,5),cv2.BORDER_DEFAULT)

import cv2

img = cv2.imread('/home/mao/Desktop/lena.jpeg')
#show origin image
cv2.imshow("origin image", img)
cv2.waitKey()
cv2.destroyAllWindows()

img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
#show grayscale image
cv2.imshow("grayscale image", img_grayscale)
cv2.waitKey()
cv2.destroyAllWindows()

ret, img_threshold = cv2.threshold(img_grayscale, 127, 255, cv2.THRESH_BINARY)
#show grayscale threshold image
cv2.imshow("grayscale threshold image", img_threshold)
cv2.waitKey()
cv2.destroyAllWindows()

img_GaussianBlur = cv2.GaussianBlur(img,(5,5),cv2.BORDER_DEFAULT)
#show GaussianBlur image
cv2.imshow("GaussianBlur image", img_GaussianBlur)
cv2.waitKey()
cv2.destroyAllWindows()

img_half = cv2.resize(img, (int(img.shape[0]/2), int(img.shape[1]/2)))
#show half of the origin image
cv2.imshow("half of the origin image", img_half)
cv2.waitKey()
cv2.destroyAllWindows()
```

3. 颜色空间转换和阈值化
```
cv2.cvtColor()   可以转化成grayscale
cv2.threshold()   可以对图像进行二值转化
```
[opencv: 阈值处理(cv2.threshold) 探究(图示+源码)](https://blog.csdn.net/JNingWei/article/details/77747959)

4. 相机(三维视觉传感器): RGB+红外(红外发射和接收, 实现三维深度信息感知)
5. opencv读取图片是BGR的形式
6. Marr的视觉设计理论

![笔记截图-1](_v_images/20190717210834272_733893320.png =509x)
机器视觉的总体概览

![笔记截图-3](_v_images/20190717211029328_1936677839.png =509x)
从低级特征到高级特征，就像卷积神经网络一样通过不断的卷积，提取到更高级的特征

![笔记截图-4](_v_images/20190717211358622_134117498.png =509x)
通过part部分来组合成所表示的物体

![笔记截图-5](_v_images/20190717211415151_1428287251.png =509x)

![Selection_083](_v_images/20190730204122613_1575424970.png =514x)
自动提取特征+度量学习

![Selection_084](_v_images/20190730204246326_941877732.png =512x)
课程架构及组织

![Selection_085](_v_images/20190730204458570_2116100703.png =508x)
机器视觉架构及组织

##### 第二章
7. 光补偿:
![笔记截图-8](_v_images/20190718212252060_621330816.png =507x)
互补色: 颜料红+颜料青，涂在白纸上的同一点，会显示黑色，如果白纸上的字体为红色，再涂上青色背景，则会在视觉效果上形成强烈刺激,色彩对比达到最大的程度，[参考链接](https://baike.baidu.com/item/%E4%BA%92%E8%A1%A5%E8%89%B2)，光源红+光源青混合则变成白色
对比色 :互补色对比，两颜色间是180度距离，对比色对比，两颜色之间是120度距离，中差色对比则是90度距离，[参考链接](https://baike.baidu.com/item/%E5%AF%B9%E6%AF%94%E8%89%B2)

![笔记截图-7](_v_images/20190718212128777_808636261.png =509x)
RGB和CMYK颜色模型

![Selection_002](_v_images/20190718213825810_824192526.png =510x)
HSI和RGB都是三通道，如果只有单通道的话就是灰度图，三通道时，H控制纯色属性(决定是红色或者黄色等)，S控制色彩的鲜艳程度，V控制光强度
亮度I: 像素值大小，我们可以看到黑白电视(灰度图)，其实也能正常看的清楚(包含信息)，与H和S无关


![Selection_001](_v_images/20190718214841170_11245539.png =511x)
[HSV和HSI的区别](https://www.cnblogs.com/wxl845235800/p/7692542.html)

![Selection_002](_v_images/20190718214944548_1279550726.png =508x)
b, c, d对应RGB
e(对应颜色分配), g, f(可以联想黑白电视)对应HSI

程序实例和结果展示:
![Selection_087](_v_images/20190730225503142_1110475634.png =512x)
```
import cv2

img = cv2.imread('/home/mao/Desktop/lena.jpeg')
img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

cv2.imshow("origin image", img)
cv2.imshow("grayscale image", img_grayscale)
cv2.waitKey()

hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

cv2.imshow("Hue", hsv[:,:,0])
cv2.imshow("Saturation", hsv[:,:,1])
cv2.imshow("Value", hsv[:,:,2])
cv2.waitKey()

cv2.imshow("Blue", img[:,:,0])
cv2.imshow("Green", img[:,:,1])
cv2.imshow("Red", img[:,:,2])

cv2.waitKey()
cv2.destroyAllWindows()
```

![Selection_088](_v_images/20190730232111916_93610196.png =500x)
value的显示图全是白色(视频中说因为都是纯色的原因)，[参考链接](https://blog.csdn.net/taily_duan/article/details/51506776)，猜测是像素值为255的原因

![Selection_089](_v_images/20190730232211636_780331939.png =511x)
像素值计算方式

![Selection_001](_v_images/20190718230625103_249564078.png =513x)
人眼的视觉感应和照明值的关系是非线性的，所以需要Y矫正，存储时需要除以2.2(量化后进行存储)，显示时需要乘以2.2(转换为符合人的视觉特征)

### 视觉处理与分析
#### 第一章~第二章: 计算机视觉引论及数字成像系统
##### 第一章
![Selection_001](_v_images/20190720231148563_865452262.png =509x)


![Selection_002](_v_images/20190720233813752_114350975.png =506x)
图像预处理滤波可实现对输入图片去噪(噪声是图像中像素值突变的地方)等作用，为后续的分割等任务做铺垫，这里用的是传统的分割方法，深度学习里叫instance segmentation

![Selection_094](_v_images/20190731155021874_1492730674.png =505x)
给两个参考链接吧，第一个链接[A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)
第二个链接[Convolution](https://en.wikipedia.org/wiki/Convolution)，看完这两个之后，我个人觉得你对什么是卷积该有一定的了解了

![Selection_095](_v_images/20190731155628151_1678422646.png =505x)
```
cv2.blur()
```
这里的滤波器或者说卷积核的形状有3x3的正方形，有十字形的，虽然讲的只是平均滤波，但也说明滤波器可以有各种各样的形状，可以参考下面[这个链接](https://en.wikipedia.org/wiki/Gaussian_blur)，可以注意里面的bokeh effect关键词，说明了不同形状的滤波器会产生不同的效果

![Selection_097](_v_images/20190731160731075_1200107670.png =504x)
中值滤波对去除椒盐噪声很有效，看下面展示的效果图
```
cv2.medianBlur()
```
![Selection_098](_v_images/20190731160819898_1573281321.png =262x)
虽然神经网络的卷积核和这里讲到的各种滤波器没什么区别，但是卷积核融入到了整个网络中，做到了end-to-end的优化，所以起到的作用也自然比手工特征选择的滤波器更好

![Selection_003](_v_images/20190720233839696_1488770676.png =509x)
还真是第一次接触到图像形态学这个东西

![Selection_004](_v_images/20190720234221208_1867194952.png =506x)

![Selection_005](_v_images/20190720234235607_601989327.png =508x)
```
cv2.morphologyEx()
```
缺点: 信息会损失，所以有些地方可能会出现马赛克

下面是平均滤波，中值滤波，形态学运算的结果
![Selection_099](_v_images/20190731170024714_1028507289.png =515x)
```
import cv2

img = cv2.imread('/home/mao/Desktop/lena.jpeg')

#show origin image
cv2.imshow("origin image", img)
cv2.waitKey()

img_average = cv2.blur(img, (5,5))
#show average image
cv2.imshow("average image", img_average)
cv2.waitKey()

img_median = cv2.medianBlur(img, 3)
#show median image
cv2.imshow("median image", img_median)
cv2.waitKey()

img_morphology_open = cv2.morphologyEx(img, cv2.MORPH_OPEN, (3,3))
img_morphology_close = cv2.morphologyEx(img_morphology_open, cv2.MORPH_CLOSE, (3,3))
#show morphology image
cv2.imshow("morphology image", img_median)
cv2.waitKey()

cv2.destroyAllWindows()
```

![Selection_100](_v_images/20190731171857538_1422040953.png =508x)
边缘检测用的是high pass filter，之前图像的平滑使用的是low pass filter(高斯滤波)
微分(求导，求极值点)和差分(求偏导的意思)
边缘检测的本质是微分，一阶导的极值点，二阶导的过零点(Laplace算子)

![Selection_110](_v_images/20190731182227268_919221473.png =511x)
Log算子(先对图像进行高斯滤波，实现去噪，再用Laplace算子检测边缘)

![Selection_106](_v_images/20190731175632018_1765582827.png =508x)
对于为什么分X轴方向和Y轴方向的理解，区域跳变的地方存在极值点，而极值点是在边缘线上(该篇总结指的是白色对应像素值为255)的点，那么X轴方向上的极值点和Y轴方向上的极值点都是一维的，如何联系到二维的极值点呢，一维扩展成二维可以通过平移的形式(想像山脉的样子，保留一个看法，一维扩展到二维是通过组合不同维度的方式来实现的)
算子是对一阶导(极值点)或者二阶导(过零点)来说的，原始图像求导后(想象成三维图的话)，那么山峰就是极值点了，而极值点在边缘线上，如果从图像层面来看，就会出现所谓的低级特征，或者说low-level的纹理特征。至于说的有些卷积核是训练出来的，这叫自动特征提取，这需要从网络结构层面来理解，特征提取+度量学习，做到了end-to-end训练，最终得到你想要的结果(训练过程中确定参数状态，也就是确定卷核的weights)

![Selection_109](_v_images/20190731182049668_2043327419.png =509x)
噪声也是跳变点，差分(用于检测边缘，特别是Laplace算子，因为求偏导的关系)对噪声不敏感，如果不在这之前进行去噪(比如高斯滤波)那么会出现很多误检

![Selection_111](_v_images/20190731184259617_1933388742.png =504x)
噪声可以使用高斯滤波来去除，断裂可以用自动边缘连接来解决，虚检(渐变灰度，容易检测出来多个边缘)可以通过梯度幅值进行非极大值抑制(在目标检测等中也有用到Non-maximum suppression)来解决，我个人觉得，当今的很多深度学习算法，吸收了传统算法的知识点

![Selection_112](_v_images/20190731205808945_820469738.png =507x)

![Selection_113](_v_images/20190731205834203_1218227072.png =505x)

![Selection_114](_v_images/20190731205852085_428503997.png =510x)
让我想起了姿态估计里的热偏置图

![Selection_115](_v_images/20190731205906026_234013580.png =511x)

![Selection_117](_v_images/20190731205919382_1238660483.png =512x)

Sobel算子展示
![Selection_122](_v_images/20190731225641946_1068603108.png =514x)

![Selection_119](_v_images/20190731221435264_666588850.png =504x)
```
import cv2

img = cv2.imread('/home/mao/Desktop/1.png')

cv2.imshow("origin image", img)
cv2.waitKey()

img_sobel_x = cv2.Sobel(img,cv2.CV_64F,dx=1,dy=0,ksize=5)
cv2.imshow("Sobel image xorder", img_sobel_x)
cv2.waitKey()

img_sobel_y = cv2.Sobel(img,cv2.CV_64F,dx=0,dy=1,ksize=5)
cv2.imshow("Sobel image yorder", img_sobel_y)
cv2.waitKey()

img_sobel_xy = cv2.Sobel(img,cv2.CV_64F,dx=1,dy=1,ksize=5)
cv2.imshow("Sobel image xyorder", img_sobel_xy)
cv2.waitKey()
```
Laplace算子，注意该算子计算的是二阶导，对于有一定宽度的边缘，容易出现双重响应(检测出来两条边缘)，[参考链接](https://blog.csdn.net/li_wen01/article/details/72864291)
![Selection_120](_v_images/20190731221904022_606983186.png =509x)
```
img_laplace = cv2.Laplacian(img,cv2.CV_64F)
cv2.imshow("Laplace image", img_laplace)
cv2.waitKey()
```
Canny算子
![Selection_121](_v_images/20190731222423399_867142287.png =509x)
最后的总代码如下，我们可以看到canny算子检测出来的边缘线更加的细，这说明Noise Reduction，Finding Intensity Gradient of the Image，Non-maximum Suppression，Hysteresis Thresholding起到作用了，[参考链接](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html)
![Selection_123](_v_images/20190731233301029_231875528.png =506x)
上图是加了高斯滤波之后检测出来的
```
import cv2

img = cv2.imread('/home/mao/Desktop/lena.jpeg')

cv2.imshow("origin image", img)
cv2.waitKey()

img = cv2.GaussianBlur(img,(3,3),cv2.BORDER_DEFAULT)

img_sobel_x = cv2.Sobel(img,cv2.CV_64F,dx=1,dy=0,ksize=5)
cv2.imshow("Sobel image xorder", img_sobel_x)
cv2.waitKey()

img_sobel_y = cv2.Sobel(img,cv2.CV_64F,dx=0,dy=1,ksize=5)
cv2.imshow("Sobel image yorder", img_sobel_y)
cv2.waitKey()

img_sobel_xy = cv2.Sobel(img,cv2.CV_64F,dx=1,dy=1,ksize=5)
cv2.imshow("Sobel image xyorder", img_sobel_xy)
cv2.waitKey()

img_laplace = cv2.Laplacian(img,cv2.CV_64F)
cv2.imshow("Laplace image", img_laplace)
cv2.waitKey()

img_canny = cv2.Canny(img,100,200)
cv2.imshow("Canny image", img_canny)
cv2.waitKey()
cv2.destroyAllWindows()
```

8. brightness和contrast

![Selection_001](_v_images/20190722140806475_1553988390.png =509x)
几种不同对比度的灰度直方图
![Selection_002](_v_images/20190722142731614_1423040128.png =515x)

![Selection_126](_v_images/20190801000033371_1430546377.png =506x)
这里的话，使用的是递归的两种方式(广度和深度，不太了解的话去搜索下吧)

![Selection_127](_v_images/20190801000157906_1066765487.png =506x)
上图是全局分割的大津算法和局部分割算法的结果图

![Selection_005](_v_images/20190722150717149_107971708.png =513x)
对平移，旋转和比例缩放变换不敏感，这个在卷积神经网络中是个很重要的点

![Selection_006](_v_images/20190722153221504_1554097180.png =507x)
几种分割方法吧，后面没显示出来的是基于深度学习的分割方法，感兴趣的去搜索instance segmentation

![Selection_130](_v_images/20190801003307518_1492204963.png =501x)
就当做随便看看吧

米粒分割结果展示
![Selection_132](_v_images/20190801011528854_1639489760.png =514x)
```
import cv2
import copy

img = cv2.imread('/home/mao/Desktop/1.jpeg')
cv2.imshow("origin image", img)
cv2.waitKey()

#转化为灰度图, 用于区域分割
img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

#使用大津算法进行阈值分割
_, bw = cv2.threshold(img, 0, 0xff, cv2.THRESH_OTSU)
cv2.imshow("otsu threshold image", bw)
cv2.waitKey()

#定义一个十字形的滤波器
element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))
#使用开运算, 分格开粘连在一起的物体
bw = cv2.morphologyEx(bw, cv2.MORPH_OPEN, element)

seg = copy.deepcopy(bw)
#得到分割完后的各个区域的轮廓
cnts, hier = cv2.findContours(seg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
count =0

for i in range(len(cnts), 0, -1):
    c = cnts[i-1]
    #计算区域面积
    area = cv2.contourArea(c)
    if area < 10:
        continue
    count = count + 1
    print("blob", i, " : ", area)
    #使用长方形来拟合米粒，并获取左顶点坐标和对应的长宽
    x,y,w,h = cv2.boundingRect(c)
    cv2.rectangle(img, (x,y), (x+w, y+h), (0,0,0xff), 1)
    cv2.putText(img, str(count), (x,y), cv2.FONT_HERSHEY_PLAIN, 0.5, (0,0xff,0))

print("米粒数量: ", count)
cv2.imshow("show result", img)

cv2.waitKey()
cv2.destroyAllWindows()
```

![Selection_001](_v_images/20190723170246953_366700469.png =509x)

![Selection_002](_v_images/20190723170258665_1502419246.png =511x)

SURF实现特征点提取与匹配
![Selection_003](_v_images/20190724163351812_1654604424.png =509x)

![Selection_004](_v_images/20190724163631055_1826101536.png =504x)

光流估计
![Selection_005](_v_images/20190724165537717_1008369455.png =508x)

背景静止时的建模方法
![Selection_006](_v_images/20190724175751322_715582824.png =511x)

特征点提取, 特征点描述, 特征点匹配